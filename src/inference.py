# ==========================================
# RECSYS_PROJECT/src/inference.py
# Robust Production Inference Engine
# Arrow / LargeUtf8 FULLY SAFE â€“ Cloud Stable Edition
# ==========================================

import pickle
import faiss
import gdown
import numpy as np
import pandas as pd
from scipy import sparse
from pathlib import Path
import logging
import io

from src.als.recommend import ALSRecommender
from src.content_based.search import ContentSearcher
from src.hybrid.hybrid import HybridRecommender

# ==========================================
# Logging
# ==========================================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
)
logger = logging.getLogger(__name__)

# ==========================================
# Runtime Cache Directory
# ==========================================
CACHE_DIR = Path("/tmp/recsys_cache")
CACHE_DIR.mkdir(parents=True, exist_ok=True)

# ==========================================
# Google Drive Files
# ==========================================
GDRIVE_FILES = {
    "faiss.index": "https://drive.google.com/uc?id=1Ls_O-Mk4HcVD8rwK-eETDpOCCUFTsb3A",
    "item_features.npy": "https://drive.google.com/uc?id=1tWBmtp0SoO7t0ef_Wei55-ekvbv-DeAA",
    "clean_interactions.parquet": "https://drive.google.com/uc?id=1THrU5p0QebN5eTnLwV3iR8s8b77vdhdu",
    "clean_movies.parquet": "https://drive.google.com/uc?id=1m_IZTPLvf7AKvS3tay6jj1ZKZKRdJyT6",
}

# ==========================================
# Helpers
# ==========================================
def _safe_remove(path: Path):
    try:
        if path.exists():
            path.unlink()
    except Exception:
        pass

def download_if_needed(filename: str, force: bool = False) -> Path:
    path = CACHE_DIR / filename
    if force:
        _safe_remove(path)
    if not path.exists():
        logger.info(f"â¬‡ï¸ Downloading {filename}")
        gdown.download(GDRIVE_FILES[filename], str(path), quiet=False, fuzzy=True)
    if not path.exists() or path.stat().st_size < 1024:
        raise RuntimeError(f"âŒ Invalid or empty file: {filename}")
    return path

# ==========================================
# Arrow / LargeUtf8 Safe
# ==========================================
def sanitize_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """Convert all columns to str to avoid Arrow / LargeUtf8 issues"""
    df_copy = df.copy()
    for col in df_copy.columns:
        df_copy[col] = df_copy[col].astype(str)
    return df_copy

def safe_read_parquet(path: Path) -> pd.DataFrame:
    df = pd.read_parquet(path)
    return sanitize_dataframe(df)

# ==========================================
# NPZ Loader
# ==========================================
def load_npz_as_npy_safe(path: Path) -> np.ndarray:
    try:
        with np.load(path) as data:
            if "data" not in data:
                raise ValueError("Missing 'data' key in NPZ")
            return data["data"]
    except Exception:
        logger.warning(f"âš ï¸ Corrupted NPZ detected: {path.name} â†’ retrying")
        _safe_remove(path)
        path = download_if_needed(path.name, force=True)
        with np.load(path) as data:
            return data["data"]

# ==========================================
# Recommender Engine
# ==========================================
class RecommenderEngine:
    def __init__(self):
        logger.info("ğŸš€ Initializing Recommender Engine")
        self._load_data()
        self._load_models()
        self._build_als_engine()
        self._build_content_engine()
        self._build_hybrid_engine()
        logger.info("âœ… Recommender Engine Ready")

    # --------------------------------------
    # Load Display Data
    # --------------------------------------
    def _load_data(self):
        movies_path = download_if_needed("clean_movies.parquet")
        self.movies = sanitize_dataframe(pd.read_parquet(movies_path))
        # Ensure movieId is string for safe merge
        self.movies["movieId"] = self.movies["movieId"].astype(str)

    # --------------------------------------
    # Load Models
    # --------------------------------------
    def _load_models(self):
        logger.info("ğŸ”„ Loading models")
        BASE_DIR = Path(__file__).resolve().parents[1]
        MODELS_DIR = BASE_DIR / "models"

        def load_pickle(name: str):
            path = MODELS_DIR / name
            if not path.exists():
                raise FileNotFoundError(f"âŒ Missing model file: {name}")
            with open(path, "rb") as f:
                return pickle.load(f)

        self.als_model = load_pickle("als_model.pkl")
        self.tfidf = load_pickle("tfidf.pkl")
        self.mlb = load_pickle("mlb.pkl")
        self.item_map = load_pickle("item_map.pkl")
        self.user_map = load_pickle("user_map.pkl")
        self.movieId_to_index = load_pickle("movieId_to_index.pkl")
        self.inv_item_map = {v: k for k, v in self.item_map.items()}

        faiss_path = download_if_needed("faiss.index")
        self.faiss_index = faiss.read_index(str(faiss_path))

        features_path = download_if_needed("item_features.npy")
        self.item_features = load_npz_as_npy_safe(features_path)

        sparse_path = MODELS_DIR / "X_sparse.npz"
        if not sparse_path.exists():
            raise FileNotFoundError("âŒ X_sparse.npz not found")
        self.X_sparse = sparse.load_npz(sparse_path)

        logger.info("âœ… Models loaded successfully")

    # --------------------------------------
    # ALS Engine
    # --------------------------------------
    def _build_als_engine(self):
        self.als_engine = ALSRecommender(
            model=self.als_model,
            X=self.X_sparse,
            user_map=self.user_map,
            item_map=self.item_map,
            inv_item_map=self.inv_item_map
        )

    # --------------------------------------
    # Content Engine
    # --------------------------------------
    def _build_content_engine(self):
        train_path = download_if_needed("clean_interactions.parquet")
        train_df = safe_read_parquet(train_path)
        self.content_engine = ContentSearcher(
            train_df=train_df,
            item_features=self.item_features,
            faiss_index=self.faiss_index,
            movieId_to_index=self.movieId_to_index,
            index_to_movieId={v: k for k, v in self.movieId_to_index.items()}
        )

    # --------------------------------------
    # Hybrid Engine
    # --------------------------------------
    def _build_hybrid_engine(self):
        train_path = download_if_needed("clean_interactions.parquet")
        train_df = safe_read_parquet(train_path)
        self.hybrid_engine = HybridRecommender(
            als_recommender=self.als_engine,
            content_searcher=self.content_engine,
            train_df=train_df
        )

    def _format_output(self, recs):
        if recs is None or len(recs) == 0:
            return pd.DataFrame()
        
        # Ø§Ø¬Ø¹Ù„ movieId Ù…Ù† ÙƒÙ„Ø§ Ø§Ù„Ø¬Ø¯ÙˆÙ„ÙŠÙ† str
        recs_df = pd.DataFrame(recs, columns=["movieId", "score"])
        recs_df["movieId"] = recs_df["movieId"].astype(str)
        self.movies["movieId"] = self.movies["movieId"].astype(str)
        
        df = recs_df.merge(self.movies, on="movieId", how="left")
        
        # Ø§Ø¬Ø¹Ù„ ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© str Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… Ø¸Ù‡ÙˆØ± LargeUtf8
        for col in df.columns:
            df[col] = df[col].astype(str)
        
        # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ù…Ù† CSV ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø¹Ø±Ø¶
        buffer = io.StringIO()
        df.to_csv(buffer, index=False)
        buffer.seek(0)
        return pd.read_csv(buffer)


    # --------------------------------------
    # APIs
    # --------------------------------------
    def recommend_als(self, user_id, top_k=10):
        return self._format_output(self.als_engine.recommend_als(user_id, top_k))

    def recommend_content(self, user_id, top_k=10):
        return self._format_output(self.content_engine.recommend(user_id, top_k))

    def recommend_hybrid(self, user_id, top_k=10, alpha=0.7):
        return self._format_output(self.hybrid_engine.recommend_weighted(user_id, top_k, alpha))


